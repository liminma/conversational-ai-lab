{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2488a46d-4741-47df-8265-d3ae7fe9efae",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'Experiment ReAct using Llama 2'\n",
    "date: 2023-08-01\n",
    "categories: [Llama 2, ReAct, Agent]\n",
    "toc: true\n",
    "highlight-style: github\n",
    "format:\n",
    "    html:\n",
    "        code-overflow: wrap\n",
    "bibliography: ../references.bib\n",
    "csl: ../ieee.csl\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1deb4-d8be-43ae-bbd4-66803ca98006",
   "metadata": {},
   "source": [
    "ReAct [@yao2022react] is a method that uses Large Language Models (LLMs) to create reasoning and actions for tasks in an interleaved way. Reasoning helps the model to create, monitor and adjust action plans and handle exceptions. Actions allows the model to access knowledge bases or external environments to obtain more information to support its reasoning.\n",
    "\n",
    "This notebook uses LangChain agent to try ReAct using Llama 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18dc92b9-4402-461a-bce1-6dce5f5a7d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36378800-7cf3-4c6c-a577-6e1584e671eb",
   "metadata": {},
   "source": [
    "## Load Llama 2 13B-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f030f91-114b-4d91-9c60-38d80e89e914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Configure HuggingFace token (click to toggle the content)\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcafee5-3215-4a14-b8b3-69e22de63f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d38b5c0b9a4e3395fc5abf0422d0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c779a3c91a8b40538a2da46f75f32478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9c2ce3db7a48408ccb562146a5478e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3719eadcd65d4bd7ac2a75e7680e1270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Load the model (click to toggle the content)\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, GenerationConfig\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "\n",
    "gen_config = GenerationConfig.from_pretrained(\n",
    "    model_id,\n",
    "    token=hf_token\n",
    ")\n",
    "gen_config.max_new_tokens = 4096\n",
    "gen_config.temperature = 0.0\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model_id,\n",
    "    return_full_text=True,\n",
    "    generation_config=gen_config,\n",
    "    device_map='auto',\n",
    "    model_kwargs={\n",
    "        'load_in_4bit': True,\n",
    "        'bnb_4bit_quant_type': 'nf4',\n",
    "        'bnb_4bit_use_double_quant': True,\n",
    "        'bnb_4bit_compute_dtype': torch.bfloat16,\n",
    "    },\n",
    "    use_auth_token=hf_token,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d5fd89-4353-47ee-86e6-7236c96fe3b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set up LangChain ReAct doc store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2dbca6-1b29-419f-9078-70d9246a7df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Initialize an agent (click to toggle the content)\n",
    "\n",
    "from langchain import Wikipedia\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "\n",
    "\n",
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=docstore.search,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Lookup\",\n",
    "        func=docstore.lookup,\n",
    "        description=\"useful for when you need to ask with lookup\",\n",
    "    )\n",
    "]\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.REACT_DOCSTORE,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084311a-be3f-47f3-b23f-3de335eec2c2",
   "metadata": {},
   "source": [
    "## Ask some questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbf6d45-4542-4704-9795-0bef14f85619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search Barbenheimer phenomenon, find the movies that caused it, and find the directors of those movies.\n",
      "Action: Search[Barbenheimer phenomenon]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBarbenheimer ( BARB-ən-HIGH-mər) is an Internet phenomenon that began circulating on social media before the simultaneous theatrical release of two blockbuster films, Barbie and Oppenheimer, on July 21, 2023, in the United States and several other countries. The word is a portmanteau of the films' titles. The dichotomy of Barbie—a fantasy comedy by Greta Gerwig about the fashion doll Barbie—and Oppenheimer—an epic biographical thriller by Christopher Nolan about physicist J. Robert Oppenheimer, scientific director of the Manhattan Project, which developed the first nuclear weapons during World War II—prompted a comedic response from Internet users, including memes and merchandise. Polygon described the two films as \"extreme opposites\", and Variety called the phenomenon \"the movie event of the year\".The films' simultaneous release was initially an instance of counterprogramming. As their release date approached, instead of Barbenheimer creating a rivalry, many suggestions to watch the films as a double feature emerged—as well as in what order to watch them—and cast members of both responded by encouraging audiences to watch the films on the same day. Celebrity participation in this trend included actor Tom Cruise, who purchased tickets to watch both while his latest film, Mission: Impossible – Dead Reckoning Part One, was scheduled to be still playing in theaters.\n",
      "Both films received widespread acclaim, and exceeded box-office expectations. While the phenomenon began as a joke about the two films' seemingly endless differences, some media commentators have pointed out some similarities between them; both films have been analyzed as exploring existentialism and the theoretical notion of the Anthropocene, both have an Oscar-nominated director and screenwriter and a large ensemble cast, and both were produced by a husband-and-wife production company.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The directors of the movies that caused the Barbenheimer phenomenon are Greta Gerwig and Christopher Nolan.\n",
      "Action: Finish[Greta Gerwig and Christopher Nolan]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Greta Gerwig and Christopher Nolan'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_agent.run('Who are the directors of the movies that caused the Barbenheimer phenomenon?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96db53e0-c515-4f3c-8d52-8b4e28ae398f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search the original transformer model, find the authors of the paper that proposed it.\n",
      "Action: Search[original transformer model]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA Transformer is a deep learning architecture that relies on the parallel multi-head attention mechanism. The original Transformer was proposed in the 2017 paper titled 'Attention Is All You Need' by Ashish Vaswani et al, Google Brain team. It is notable for requiring less training time compared to previous recurrent neural architectures, such as long short-term memory (LSTM), and its later variation has been prevalently adopted for training large language models on large (language) datasets, such as the Wikipedia Corpus and Common Crawl, by virtue of the parallelized processing of input sequence.\n",
      "Input text is parsed into tokens by a byte pair encoding tokenizer, and each token is converted into a vector via looking up from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via parallel multi-head attention mechanism. Though the Transformer model came out in 2017, the core attention mechanism was proposed earlier in 2014 by Bahdanau, Cho, and Bengio for machine translation.\n",
      "This architecture is now used not only in natural language processing, computer vision, but also in audio, and multi-modal processing. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (Bidirectional Encoder Representations from Transformers).\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The authors of the paper that proposed the original transformer model are Ashish Vaswani et al, Google Brain team.\n",
      "Action: Finish[Ashish Vaswani et al]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ashish Vaswani et al'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_agent.run('Who are the authors of the paper that proposed the original transformer model?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549163c0-5d75-4e2c-8f52-e7cc4dbad6cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search Terminator, find what it is about, and provide my answer.\n",
      "Action: Search[Terminator]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe Terminator is a 1984 American science fiction action film directed by James Cameron. It stars Arnold Schwarzenegger as the Terminator, a cyborg assassin sent back in time from 2029 to 1984 to kill Sarah Connor (Linda Hamilton), whose unborn son will one day save mankind from extinction by Skynet, a hostile artificial intelligence in a post-apocalyptic future. Kyle Reese (Michael Biehn) is a soldier sent back in time to protect Sarah. The screenplay is credited to Cameron and producer Gale Anne Hurd, while co-writer William Wisher Jr. received an \"additional dialogue\" credit.\n",
      "Cameron devised the premise of the film from a fever dream he experienced during the release of his first film, Piranha II: The Spawning (1982), in Rome, and developed the concept in collaboration with Wisher. He sold the rights to the project to fellow New World Pictures alumna Hurd on the condition that she would produce the film only if he were to direct it; Hurd eventually secured a distribution deal with Orion Pictures, while executive producers John Daly and Derek Gibson of Hemdale Film Corporation were instrumental in setting up the film's financing and production. Originally approached by Orion for the role of Reese, Schwarzenegger agreed to play the title character after befriending Cameron. Filming, which took place mostly at night on location in Los Angeles, was delayed because of Schwarzenegger's commitments to Conan the Destroyer (1984), during which Cameron found time to work on the scripts for Rambo: First Blood Part II (1985) and Aliens (1986). The film's special effects, which included miniatures and stop-motion animation, were created by a team of artists led by Stan Winston and Gene Warren Jr.\n",
      "Defying low pre-release expectations, The Terminator topped the United States box office for two weeks, eventually grossing $78.3 million against a modest $6.4 million budget. It is credited with launching Cameron's film career and solidifying Schwarzenegger's status as a leading man. The film's success led to a franchise consisting of several sequels, a television series, comic books, novels and video games. In 2008, The Terminator was selected by the Library of Congress for preservation in the United States National Film Registry.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The Terminator is a 1984 American science fiction action film directed by James Cameron, starring Arnold Schwarzenegger as the Terminator, a cyborg assassin sent back in time to kill Sarah Connor, whose unborn son will one day save mankind from extinction by Skynet, a hostile artificial intelligence in a post-apocalyptic future.\n",
      "Action: Finish[The Terminator is a 1984 American science fiction action film directed by James Cameron, starring Arnold Schwarzenegger as the Terminator, a cyborg assassin sent back in time to kill Sarah Connor, whose unborn son will one day save mankind from extinction by Skynet, a hostile artificial intelligence in a post-apocalyptic future.]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Terminator is a 1984 American science fiction action film directed by James Cameron, starring Arnold Schwarzenegger as the Terminator, a cyborg assassin sent back in time to kill Sarah Connor, whose unborn son will one day save mankind from extinction by Skynet, a hostile artificial intelligence in a post-apocalyptic future.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_agent.run(\"What is the movie Terminator about? Use your findings as your answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b7394-9aa6-4f9d-a30f-3bce23d37456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
