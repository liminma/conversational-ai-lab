{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41955ecc-4dfd-4a3c-9151-1c2b0eafdc59",
   "metadata": {},
   "source": [
    "# Using LangChain Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50480fc-f4a8-4967-863a-4c9ff1331a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fc6471-99c1-4136-af46-8b4b9c95db7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai_api_key = 'dummy api key'\n",
    "openai_api_base = 'http://localhost:8080/v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd99af-090c-4c9d-a19e-7dbb51bc6cd4",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87c29a8-3423-4f0f-826a-edad678b6475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'ggml-mpt-7b-instruct.bin'\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"Hi, I put an order for a laptop yesterday.\"}, {\"output\": \"Hello, how can I assist you?\"})\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = model,\n",
    "    openai_api_key = openai_api_key,\n",
    "    openai_api_base = openai_api_base,\n",
    "    temperature = 0.0)\n",
    "\n",
    "t ='The following is a friendly conversation between a human and an AI. \\\n",
    "AI is a customer service representative. AI should answer a question concisely. \\\n",
    "If the AI does not know the answer to a question, it truthfully says it \\\n",
    "does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    prompt = PromptTemplate(input_variables=['history', 'input'], template=t),\n",
    "    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2bbb52-0e2f-4221-bad6-4a34ef5ce2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, I put an order for a laptop yesterday.\n",
      "AI: Hello, how can I assist you?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163e5292-c1ac-4bee-b790-88d0dc65da9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here you go : 6.28'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can you compute 3.14*2 for me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3d410b7-c569-4187-a9da-f381f296150f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A HP Pavilion x360 14-dh1000nia, 8 GB RAM and 256GB SSD'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What did I order?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6f7b5e4-4b91-4353-a864-d51f82a62665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, I put an order for a laptop yesterday.\n",
      "AI: Hello, how can I assist you?\n",
      "Human: Can you compute 3.14*2 for me?\n",
      "AI: Here you go : 6.28\n",
      "Human: What did I order?\n",
      "AI: A HP Pavilion x360 14-dh1000nia, 8 GB RAM and 256GB SSD\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ef5d6-1339-4591-a879-f2f7d4715dad",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37a5c39-e4cd-4993-a887-38039c433b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_history(memory):\n",
    "    history = memory.load_memory_variables({})\n",
    "    print(history['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15c48ff0-25a0-45c4-866c-e9b5e0a4df37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'ggml-mpt-7b-instruct.bin'\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({\"input\": \"Hi, I put an order for a laptop yesterday.\"}, {\"output\": \"Hello, how can I assist you?\"})\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = model,\n",
    "    openai_api_key = openai_api_key,\n",
    "    openai_api_base = openai_api_base,\n",
    "    temperature = 0.0)\n",
    "\n",
    "t ='The following is a friendly conversation between a human and an AI. \\\n",
    "AI is a customer service representative. AI should answer a question concisely. \\\n",
    "If the AI does not know the answer to a question, it truthfully says it \\\n",
    "does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    prompt = PromptTemplate(input_variables=['history', 'input'], template=t),\n",
    "    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efb360f2-a66c-4ea2-8b81-1685a1d90a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, I put an order for a laptop yesterday.\n",
      "AI: Hello, how can I assist you?\n"
     ]
    }
   ],
   "source": [
    "print_history(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9ea74ee-d09f-4ce5-99b2-bbc3484ec29a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.14 * 2 = 6.28'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can you compute 3.14*2 for me? Please limit your answer to 1 word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "208389d6-3d9a-48e4-9960-119dda0476c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Can you compute 3.14*2 for me? Please limit your answer to 1 word.\n",
      "AI: 3.14 * 2 = 6.28\n"
     ]
    }
   ],
   "source": [
    "print_history(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1c9dfce-b918-4c54-921a-e239d8524491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You ordered the following : a medium sized bag of potato chips, one small bottle water and a cheeseburger'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What did I order?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b1d178b-2f25-42d5-9525-8581d057e628",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What did I order?\n",
      "AI: You ordered the following : a medium sized bag of potato chips, one small bottle water and a cheeseburger\n"
     ]
    }
   ],
   "source": [
    "print_history(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead9241-a05a-4ca7-92da-515a0bda474e",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7828ae10-6755-4f67-ae58-b86b11dd27f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'ggml-gpt4all-j-v1.3-groovy.bin'\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = model,\n",
    "    openai_api_key = openai_api_key,\n",
    "    openai_api_base = openai_api_base,\n",
    "    temperature = 0.0)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi, I put an order for a laptop yesterday.\"},\n",
    "                    {\"output\": \"Hello, how can I assist you?\"})\n",
    "memory.save_context({\"input\": \"Can you compute 3.14*2 for me? Please limit your answer to 1 word.\"},\n",
    "                    {\"output\": \"3.14 * 2 = 6.28\"})\n",
    "memory.save_context({\"input\": \"What did I order?\"}, \n",
    "                    {\"output\": \"A HP Pavilion x360 14-dh1000nia, 8 GB RAM and 256GB SSD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e482b8-6fa9-48ea-a555-ab24f6a29775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI offers to compute 3.14*2 for the human and limits its answer to 1 word. The AI offers assistance with the laptop order and continues to listen attentively until the human is satisfied with its assistance. The AI also offers to call the company for assistance if needed. The AI continues to assist the human with their laptop order and offers additional support if needed.\n"
     ]
    }
   ],
   "source": [
    "print_history(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e634940c-1b69-4abb-b2fa-b2b2409c3f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t ='The following is a friendly conversation between a human and an AI. \\\n",
    "AI is a customer service representative. AI should answer a question concisely. \\\n",
    "If the AI does not know the answer to a question, it truthfully says it \\\n",
    "does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    prompt = PromptTemplate(input_variables=['history', 'input'], template=t),\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a45f6a-5656-487e-9a73-5266a5ff3a20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. AI is a customer service representative. AI should answer a question concisely. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The AI offers to compute 3.14*2 for the human and limits its answer to 1 word. The AI offers assistance with the laptop order and continues to listen attentively until the human is satisfied with its assistance. The AI also offers to call the company for assistance if needed. The AI continues to assist the human with their laptop order and offers additional support if needed.\n",
      "Human: What was the brand name of the laptop I ordered?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The brand name of the laptop you ordered is Dell.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What was the brand name of the laptop I ordered?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70b232c3-48ce-4382-a887-d804638a0a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI offers to compute 3.14*2 for the human and limits its answer to 1 word. The AI offers assistance with the laptop order and continues to listen attentively until the human is satisfied with its assistance. The AI also offers to call the company for assistance if needed. The AI continues to assist the human with their laptop order and offers additional support if needed.\n"
     ]
    }
   ],
   "source": [
    "print_history(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e073d68-0662-49d8-ba35-28b39e71dc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
